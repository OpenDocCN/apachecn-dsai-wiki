# 三、基于深度学习的推荐：最先进的技术

在本节中，我们首先介绍基于深度学习的推荐模型的类别，然后突出最先进的研究原型，旨在确定近年来最显着和最有希望的进步。

## 基于深度学习的推荐模型的类别

**图 1：**基于深度神经网络的推荐模型的类别。

![](img/fig1.jpg)

为了提供该领域的全景图，我们根据所采用的深度学习技术的类型对现有模型进行分类。 我们进一步将基于深度学习的推荐模型分为以下两类。 表 1 总结了分类方案。

**表 1：**已回顾论文的查找表。

| 分类 | 论文 |
| --- | --- |
| MLP | [2,13,20,27,38,47,53,54,66,92,95,157,166,185]， [12,39,93,112,134,154,182,183] |
| 自编码器 | [34,88,89,114,116,125,136,137,140,159,177,187,207]， [4,10,32,94,150,151,158,170,171,188,196,208,209] |
| CNN | [25,49,50,75,76,98,105,127,130,153,165,172,202,206]， [6,41,51,83,110,126,143,148,169,190,191] |
| RNN | [5,28,35,36,56,57,73,78,90,117,132,139,142,174-176]， [24,29,33,55,68,91] |
| RBM | [42,71,72,100,123,167,180] |
| NADE | [36,203,204] |
| 神经注意力 | [14,44,70,90,117,132,139,142,164-176]， [62,146,193] |
| 对抗网络 | [9,52,162,164] |
| DRL | [16,21,107,168,198-200] |
| 混合模型 | [17,38,41,82,84,87,118,135,160,192,193] |

*   使用神经积木的推荐 。 在该类别中，模型根据上述八种深度学习模型分为八个子类别：基于MLP，AE，CNN，RNN，RBM，NADE，AM，AN和DRL的推荐系统。 使用的深度学习技术决定了推荐模型的适用性。 例如，MLP可以轻松地模拟用户和项目之间的非线性交互；CNN能够从异构数据源（例如文本和视觉信息）中提取局部和全局表示；RNN使推荐系统能够建模内容信息的时间动态和连续演化。
*   使用深度混合模型的推荐。 一些基于深度学习的推荐模型使用多种深度学习技术。 深度神经网络的灵活性使得将几个神经积木组合在一起来相互补充，并形成更强大的混合模型成为可能。 这些深度学习技术有许多可能的组合，但并非所有技术都被利用。 请注意，它与[31]中的混合深度网络不同，后者指的是利用生成和判别成分的深层架构。

**表 2：**特定应用领域中基于深度神经网络的推荐模型。

| 数据 来源/任务 | 注 | 论文 |
| --- | --- | --- |
| 序列信息 | w/t 用户 ID | [16, 29, 33, 35, 73, 91, 117, 133, 143, 160, 173, 175, 189, 194, 198, 205] |
|  | 基于会话的 w/t 用户 ID | [55–57, 68, 73, 99, 101, 102, 117, 142, 148, 149] |
|  | 登入，POI | [150, 151, 165, 185] |
| 文本 | 哈希标签 | [44, 110, 118, 158, 182, 183, 193, 209] |
|  | 新闻 | [10, 12, 113, 135, 169, 200] |
|  | 评论文本 | [11, 87, 126, 146, 174, 197, 202] |
|  | 引言 | [82, 141] |
| 图片 | 视觉特征 | [2, 14, 25, 49, 50, 84, 98, 105, 112, 165, 172, 179, 191, 192, 197, 206] |
| 音频 | 音乐 | [95, 153, 167, 168] |
| 视频 | 影片 | [14, 17, 27, 83] |
| 网络 | 引文网 | [9, 38, 66] |
|  | 社交网络 | [32, 116, 166] |
|  | 跨域 | [39, 92, 166] |
| 其它 | 冷启动 | [154, 156, 170, 171] |
|  | 多任务 | [5, 73, 87, 174, 187] |
|  | 解释 | [87, 126] |

表 1 列出所有回顾的模型，我们按照上述分类方案组织它们。 此外，我们还在表 2 中从任务角度总结了一些论文。 回顾的论文涉及各种任务。 由于使用深度神经网络（例如基于会话的推荐，图像，视频推荐），一些任务已开始受到关注。 一些任务对于推荐研究领域可能并不新颖（用于推荐系统的辅助信息的详细回顾可以在[131]中找到），但DL提供了更多找到更好解决方案的可能性。 例如，如果没有深度学习技巧的帮助，处理图像和视频将是一项艰巨的任务。 深度神经网络的序列建模功能可以轻松捕获用户行为的序列模式。 一些具体任务将在下文中讨论。

## 基于多层感知器的推荐

MLP是一个简洁但有效的网络，据证明能够以任何所需的准确度近似将任何可测量的函数[59]。 因此，它是许多先进方法的基础，并且在许多领域中被广度使用。

传统推荐方法的神经扩展。 许多现有的推荐模型基本上是线性方法。 MLP可用于向现有RS方法添加非线性变换并将其解释为神经扩展。

**图 2：**图示：（a）神经协同过滤；（b）深度分解机。

![](img/fig2.jpg)

神经协同过滤 。 在大多数情况下，推荐被视为用户偏好和项目特征之间的双向交互。 例如，矩阵分解将评分矩阵分解为低维用户/项目潜在因子。 构建双神经网络来模拟用户和项目之间的双向交互是很自然的。 神经网络矩阵分解（NNMF）[37]和神经协同过滤（NCF）[53]是两个具有代表性的工作。 图 2a 显示了NCF架构。 让 ![](img/img16.png) 和 ![](img/img17.png) 表示辅助信息（例如用户个人信息和项目特征），或者仅表示用户 ![](img/img6.png) 和项目 ![](img/img7.png) 的单热标识符。 评分函数定义如下：

![](img/img18.png) (1)

其中函数 ![](img/img19.png) 代表多层感知器， ![](img/img20.png) 是这个网络的参数。 传统的MF可以被视为NCF的一个特例。 因此，将矩阵分解的神经解释与MLP融合来制定更通用的模型是方便的，该模型利用MF的线性和MLP的非线性来提高推荐质量。 可以使用加权平方损失（用于显式反馈）或二元交叉熵损失（用于隐式反馈）来训练整个网络。 交叉熵损失定义为：

![](img/img21.png) (2)

可以使用负采样方法来减少未观测的训练实例的数量。 后续工作[112,134]建议使用成对排名损失来提高效果。He 等 [92,166]将NCF模型扩展到跨域推荐。 Xue 等 [184]和 Zhang 等 [195]表明，可以用交互矩阵的列或行替换单热标识符来保留用户项目交互模式。

深度分解机 。 DeepFM [47]是一种端到端模型，可无缝集成分解机和MLP。 它能够使用深度神经网络和与分解机的低阶交互来建模高阶特征相互作用。 分解机（FM）利用加法和内积运算来捕获特征之间的线性和成对相互作用（更多细节参见[119]中的公式（1））。 MLP利用非线性激活和深层结构来模拟高阶交互。 MLP与FM结合的方式受到广度和深度网络的启发。 它用分解机的神经解释取代了宽的分量。 与广度和深度模型相比，DeepFM不需要繁琐的特征工程。 图 2b 说明了DeepFM的结构。  DeepFM的输入 ![](img/img22.png) 是一个 ![](img/img23.png)  个领域的数据，由 ![](img/img24.png) 对组成（用户和项目的身份和特征）。 为简单起见，FM和MLP的输出分别表示为 ![](img/img25.png) 和 ![](img/img26.png) 。 预测得分通过以下公式计算：

![](img/img27.png) (3)

其中 ![](img/img28.png) 是S形激活函数。

Lian 等 [93]通过提出一个eXtreme深度分解机来同时模拟显式和隐式特征交互，从而改进了DeepMF。 通过压缩交互网络学习显式高阶特征交互。 He等提出的并行工作  [54]取代了与MLP的二阶交互，并建议使用dropout和batch normalization对模型进行正则化。

用MLP学习特征表示。 使用MLP进行特征表示非常简单且高效，即使它可能不像自编码器，CNN和RNN那样具有表现力。

广度和深度学习 。 这个通用模型（如图 3a 所示） 可以解决回归和分类问题，但最初在Google Play的App推荐中引入[20]。 广度学习成分是单层感知器，也可以视为广义线性模型。 深度学习成分是多层感知器。 结合这两种学习技术的基本原理是，它使推荐系统能够捕获记忆和概括。 广度学习成分实现的记忆，代表了从历史数据中捕获直接特征的能力。 同时，深度学习成分通过产生更一般和抽象的表示，来捕捉泛化。 该模型可以提高推荐的准确性和多样性。

形式上，广度学习定义为： ![](img/img29.png)  ，其中 ![](img/img30.png)  ， ![](img/img31.png) 是模型参数。 输入 ![](img/img32.png) 是由原始输入特征 ![](img/img22.png) ，和变换特征 ![](img/img33.png) （例如，捕获特征之间的相关性的交叉乘积变换） 组成的连接特征集 。 深层神经元的每一层都是  ![](img/img34.png)  ，其中 ![](img/img35.png) 表示 ![](img/img36.png) 层， ![](img/img19.png) 是激活函数。  ![](img/img37.png) 和 ![](img/img38.png) 是权重和偏置。 通过融合这两个模型可以获得广度和深度学习模型：

![](img/img39.png) (4)

其中 ![](img/img28.png) 是sigmoid函数， ![](img/img8.png) 是二元评分标签， ![](img/img40.png) 是最后的激活。 该联合模型使用随机反向传播（follow-the-regularized-leader 算法）进行优化。 基于预测的分数生成推荐列表。

通过扩展这个模型，Chen 等 [13]为大规模的工业级推荐任务设计了一个局部连接的广度和深度学习模型。 它采用高效的局部连接网络来取代深度学习成分，从而将运行时间减少一个数量级。 部署广度和深度学习的一个重要步骤是选择广度和深度部分的特征。 换句话说，系统应该能够确定哪些特征被记忆或概括。 此外，还需要手工设计交叉乘积变换。 这些预先步骤将极大地影响该模型的效果。 上述基于深度因式分解的模型可以减少特征工程的工作量。

Covington等  [27]探讨了YouTube推荐中MLP的应用。 该系统将推荐任务分为两个阶段：候选生成和候选排名。 候选生成网络从所有视频语料库中检索子集（数百个）。 排名网络基于来自候选者的最近邻居分数生成 top-n 个列表（数十个）。 我们注意到工业界更关注特征工程（例如变换，正则化，交叉）和推荐模型的可扩展性。

Alashkar等 [2]提出了基于MLP的化妆品推荐模型。 这项工作使用两个相同的MLP分别为标记示例和专家规则建模。 通过最小化它们的输出之间的差异，同时更新这两个网络的参数。 它展示了采用专家知识指导MLP框架中推荐模型学习过程的效果。 即使专业知识的获取需要很多人的参与，它也是高度精确的。

**图 3：**图示：（a）广度和深度学习；（b）多视图深度神经网络。

![](img/fig3.jpg)

协同度量学习（CML） 。 CML [60]用欧几里德距离代替MF的点积，因为点积不满足距离函数的三角恒等性。 通过最大化用户与其不喜欢的项目之间的距离并最小化用户与其偏好项目之间的距离来学习用户和项目嵌入。 在CML中，MLP用于学习项目特征（如文本，图像和标签）的表示。

深度结构化语义模型的推荐。 深度结构化语义模型（DSSM）[65]是一个深度神经网络，用于学习常见连续语义空间中实体的语义表示，并测量它们的语义相似性。 它广泛应用于信息检索领域，非常适合 top-n 推荐[39,182]。 DSSM将不同的实体投射到一个共同的低维空间中，并用余弦函数计算它们的相似性。 基本的DSSM由MLP组成，因此我们将其放在本节中。 请注意，更高级的神经层（如卷积和最大池层）也可以轻松集成到DSSM中。

基于深度语义相似度的个性化推荐（DSPR） [182]是标签感知个性化推荐器，其中每个用户 ![](img/img41.png) 和项目 ![](img/img42.png) 由标记注解表示并映射到公共标记空间。 余弦相似度 ![](img/img43.png) 用于决定项目和用户的相关性（或用户对项目的偏好）。  DSPR的损失函数定义如下：

![](img/img44.png) (5)

其中 ![](img/img45.png) 是从负面用户项目对中随机抽样的负样本。[183]的作者使用自编码器进一步改进DSPR，来从用户/项目资料中学习低维表示。

多视图深度神经网络（MV-DNN） [39]专为跨域推荐而设计。 它将用户视为透视视图，每个域（假设我们有 ![](img/img46.png) 个域）作为辅助视图。 显然，对于 ![](img/img46.png) 个用户域对，有 ![](img/img46.png) 个相似度得分。 图 3b 展示了MV-DNN的结构。  MV-DNN的损失函数定义为：

![](img/img47.png) (6)

其中 ![](img/img20.png) 是模型参数， ![](img/img48.png) 是平滑因子， ![](img/img49.png) 是用户视图的输出， ![](img/img50.png) 是活动视图的索引。 ![](img/img51.png) 是视图 ![](img/img50.png)  的输入域。  MV-DNN能够扩展到许多域。 然而，它基于这样的假设：如果用户在一个域中具有某种品味，应该在其他域中具有相似的品味。 直观地说，在许多情况下，这种假设可能是不合理的。 因此，我们应该初步了解不同域之间的相关性，来充分利用MV-DNN。

## 基于自编码器的推荐

将自编码器应用于推荐系统有两种通用方法：（1）利用自编码器学习瓶颈层的低维特征表示；或者（2）直接在重构层中填充交互矩阵的空白。 几乎所有的自编码器变体，例如去噪自编码器，变分自编码器，收缩自编码器和边缘化自编码器都可以应用于推荐任务。 表 3 基于所使用的自编码器类型总结了推荐模型。

基于自编码器的协同过滤。 其中一个成功的应用是从自编码器的角度考虑协同过滤。

AutoRec [125]使用用户部分向量 ![](img/img52.png) 或项目部分向量  ![](img/img53.png) 作为输入，旨在在输出层重构它们。 显然，它有两种变体：基于项目的AutoRec（I-AutoRec）和基于用户的AutoRec（U-AutoRec），对应于两种类型的输入。 在这里，我们只介绍I-AutoRec，而U-AutoRec可以相应地轻松派生。 图 4a 说明了I-AutoRec的结构。 给定输入  ![](img/img53.png)  ，重构是：  ![](img/img54.png)  ，其中 ![](img/img19.png) 和 ![](img/img55.png) 是激活函数，![](img/img56.png) 是参数。  I-AutoRec的目标函数如下：

![](img/img57.png) (7)

这里 ![](img/img58.png) 意味着它只考虑观测的评分。 可以通过弹性传播（收敛更快并产生可比较的结果）或L-BFGS（限制记忆的Broyden Fletcher Goldfarb Shanno算法）来优化目标函数。 AutoRec的四个要点值得在部署之前注意到：（1）I-AutoRec的性能优于U-AutoRec，这可能是由于用户部分观测向量的方差较大。  （2）激活函数 ![](img/img19.png) 和 ![](img/img55.png) 的不同组合将大大影响性能。  （3）适度增加隐藏单元大小将改善结果，因为扩展隐藏层维度使AutoRec能够更好地模拟输入的特征。  （4）添加更多层来形成深层网络可以略微改进。

**图 4：**图示：（a）基于项目的AutoRec；（b）协同去噪自编码器；（c）深层协同过滤框架。

![](img/fig4.jpg)

CFN [136,137]是AutoRec的扩展，具有以下两个优点：（1）它采用了去噪技术，使CFN更加健壮；（2）它结合了诸如用户资料和项目描述之类的辅助信息，来减轻稀疏性和冷启动影响。 CFN的输入也是部分观测向量，因此它也有两种变体：I-CFN和U-CFN，![](img/img53.png) 和  ![](img/img52.png) 分别作为输入。 掩蔽噪声是正则化器，用于更好地处理缺失元素（它们的值为零）。 作者介绍了三种广泛使用的破坏方法来破坏输入：高斯噪声，掩蔽噪声和椒盐噪声。  CFN的进一步扩展还包含辅助信息。 然而，CFN不是仅仅在第一层中结合辅助信息，而是在每一层中注入辅助信息。 因此，重构变为：

![](img/img59.png) (8)

其中 ![](img/img60.png) 是辅助信息，  ![](img/img61.png) 表示  ![](img/img62.png) 和 ![](img/img60.png) 的连接。 结合辅助信息可提高预测准确性，加快训练过程并使模型更加健壮。

**表 3：**四种基于自编码器的推荐模型的总结

| 普通/去噪AE | 变分AE | 收缩AE | 边缘化AE |
| --- | --- | --- | --- |
| [114,125,136,137,159,177] [70,116,170,171,188] | [19,89,94] | [196] | [88] |

协同去噪自编码器（CDAE） 。 之前回顾的三个模型主要用于评分预测，而CDAE [177]主要用于排名预测。 CDAE的输入是用户的部分观测的隐式反馈 ![](img/img63.png)  。 如果用户喜欢电影，则条目值为1，否则为0。它还可以被视为反映用户对项目的兴趣的偏好向量。 图 4b 说明了CDAE的结构。  CDAE的输入被高斯噪声破坏。 有损输入  ![](img/img64.png) 是从条件高斯分布 ![](img/img65.png)  中提取的。重构定义为：

![](img/img66.png) (9)

其中 ![](img/img67.png) 表示用户节点的权重矩阵（见图 4B）。 该权重矩阵对于每个用户是唯一的，并且对模型性能具有显着影响。 通过最小化重构误差也可以学习CDAE的参数：

![](img/img68.png) (10)

其中损失函数 ![](img/img69.png) 可以是平方损失或 logistic 损失。

CDAE最初使用SGD在所有反馈上更新其参数。 然而，作者认为在现实世界的应用中考虑所有评分是不切实际的，因此他们提出了一种负采样技术来从负集合（用户没有与之交互的项目）中抽取一小部分，这减少了时间复杂度，但基本上没有降低排名质量。

Muli-VAE和Multi-DAE [94]提出了一种变分自编码器，用于推荐隐含数据，展示出比CDAE更好的性能。 作者介绍了一种用于参数估计的原则性贝叶斯推理方法，并且展示出比常用似然函数更好的结果。

据我们所知，基于自编码器的协同过滤（ACF）[114]是第一个基于自编码器的协同推荐模型。 它不是使用原始的部分观察向量，而是通过整数评分对它们进行分解。 例如，如果评分分数是[1-5]范围内的整数，则每个 ![](img/img53.png) 将分为五个部分向量。 与AutoRec和CFN类似，ACF的损失函数旨在减少均方误差。 然而，ACF有两个缺点：（1）它无法处理非整数评分； （2）部分观测向量的分解增加了输入数据的稀疏性，导致预测精度更差。

用自编码器学习特征表示。 自编码器是一类功能强大的特征表示学习方法。 因此，它还可以用在推荐系统中以从用户/项目内容特征学习特征表示。

协同深度学习（CDL） 。 CDL [159]是一种分层贝叶斯模型，它将栈式去噪自编码器（SDAE）集成到概率矩阵分解中。 为了无缝地结合深度学习和推荐模型，作者提出了一个通用的贝叶斯深度学习框架[161]，它由两个紧密结合的成分组成：感知成分（深度神经网络）和任务特定成分。 具体而言，CDL的感知成分是普通SDAE的概率解释，PMF充当任务特定成分。 这种紧密结合使CDL能够平衡辅助信息和交互历史的影响。 CDL的生成过程如下：

1.  对于 SDAE 的每一层 ![](img/img35.png)：（a）对于权重矩阵 ![](img/img71.png) 的每列 ![](img/img70.png)，抽取 ![](img/img72.png)； （b）抽取偏置向量 ![](img/img73.png)；（c）![](img/img74.png) 的每一行 ![](img/img7.png)，抽取 ![](img/img75.png)。
2.  对于每个项目 ![](img/img7.png) ：（a）抽取干净的输入 ![](img/img76.png)；（b）抽取潜在偏移向量  ![](img/img77.png) 并设置潜在项目向量：![](img/img78.png)。
3.  为每个用户 ![](img/img6.png) 抽取潜在的用户向量，  ![](img/img79.png)。
4.  对于每个用户 - 项目对 ![](img/img24.png)，抽取评分 ![](img/img5.png)，![](img/img80.png)。

其中 ![](img/img71.png) 和 ![](img/img81.png) 是层 ![](img/img35.png) 的权重矩阵和偏置向量， ![](img/img74.png) 代表层 ![](img/img35.png)。 ![](img/img82.png)，![](img/img83.png)，![](img/img84.png)，![](img/img85.png)，![](img/img86.png) 是超参数，![](img/img87.png) 是用于确定观察置信度的置信参数[63]。图 5（左）说明了CDL的图模型。 作者利用EM风格的算法来学习参数。 在每次迭代中，首先它都会更新 ![](img/img88.png) 和 ![](img/img89.png)，然后通过固定 ![](img/img88.png) 和 ![](img/img89.png)，更新 ![](img/img90.png) 和 ![](img/img31.png)。作者还介绍了一种基于抽样的算法[161]，来避免局部最优。

在CDL之前，Wang等 [158]提出了一个类似的模型，关系栈式去噪自编码器（RSDAE），用于标签推荐。 CDL和RSDAE的区别在于，RSDAE用关系信息矩阵替换PMF。 CDL的另一个扩展是协同变分自编码器（CVAE）[89]，它用变分自编码器代替CDL的深层神经组件。 CVAE学习内容信息的概率潜变量，并且可以轻松地合并多媒体（视频，图像）数据源。

**图 5：**协同深度学习（左）和协同深度排名（右）的图模型。

![](img/fig5.jpg)

协同深度排名（CDR） 。 CDR [188]专门为成对框架设计，用于 top-n 推荐。 一些研究表明，成对模型更适合排名列表生成[120,177,188]。 实验结果还表明，CDR在排名预测方面优于CDL。 图 5（右）介绍CDR的结构。  CDR生成过程的第一和第二步与CDL相同。 第三步和第四步由以下步骤代替：

*   对于每个用户 ![](img/img6.png)：（a）抽取潜在的用户向量 ![](img/img6.png)，![](img/img79.png)；（b）对于每对成对偏好 ![](img/img91.png)，其中 ![](img/img92.png)，抽取估算器，![](img/img93.png)。

其中 ![](img/img94.png) 表示用户对项目 ![](img/img7.png) 和项目 ![](img/img95.png) 的偏好的成对关系，![](img/img96.png) 是一个置信度值，表示比起项目 ![](img/img95.png) 用户多么 ![](img/img6.png) 喜欢项目 ![](img/img7.png)。优化过程与CDL相同。

深层协同过滤框架 。 它是使用协同过滤模型[88]来统一深度学习方法的一般框架。 该框架可以轻松利用深度特征学习技术来构建混合协同模型。 上述工作如[153,159,167]，可视为该一般框架的特例。 形式上，深层协同过滤框架定义如下：

![](img/img97.png) (11)

其中 ![](img/img98.png)，![](img/img48.png) 和 ![](img/img99.png) 是权衡参数，用于平衡这三个成分的影响， ![](img/img100.png) 和 ![](img/img101.png) 是辅助信息， ![](img/img69.png) 是协同过滤模型的损失。![](img/img102.png) 和 ![](img/img103.png) 充当铰链，用于连接深度学习和协同模型，以及将潜在因素链接到边信息。 在此框架的基础上，作者提出了基于边缘化去噪自编码器的协同过滤模型（mDA-CF）。 与CDL相比，mDA-CF探索了一种计算效率更高的自编码器变体：边缘化去噪自编码器[15]。 它通过边缘化损坏的输入，来节省搜索足够损坏的输入版本的计算开销，这使得mDA-CF比CDL更具可扩展性。 此外，mDA-CF嵌入项目和用户的内容信息，而CDL仅考虑项目特征的效果。

AutoSVD ++ [196]利用收缩自编码器[122]来学习项目特征表示，然后将它们集成到经典推荐模型SVD ++ [79]中。 所提出的模型具有以下优点：（1）与其他自编码器变体相比，收缩自编码器捕获无穷小的输入变化；（2）对隐式反馈进行建模，来进一步提高准确性；（3）设计了一种有效的训练算法，来减少训练时间。

HRCD [170,171]是基于自编码器和timeSVD ++ [80]的混合协同模型。 它是一种时间感知模型，它使用SDAE从原始特征中学习项目表示，旨在解决冷项目问题。

## 基于卷积神经网络的推荐

卷积神经网络通过卷积和池化操作处理非结构化多媒体数据非常强大。 大多数基于CNN的推荐模型利用CNN进行特征提取。

用CNN学习特征表示。 CNN可用于从多个来源学习特征表示，例如图像，文本，音频，视频等。

用于图像特征提取的CNN 。Wang 等[165]研究了视觉特征对兴趣点（POI）推荐的影响，并提出了视觉内容增强型POI推荐系统（VPOI）。 VPOI采用CNN来提取图像特征。 推荐模型建立在PMF之上，探索以下因素之间的交互：（1）视觉内容和潜在用户因素；（2）视觉内容和潜在位置因素。 Chu等 [25]在餐馆推荐中利用视觉信息（例如餐馆的食物和家具的图像）的有效性。 CNN联合提取的视觉特征与文本表示一起输入到MF，BPRMF和FM中来测试它们的表现。 结果表明，视觉信息在一定程度上改善了表现，但并不显着。 He等 [50]通过将视觉特征（通过CNN学习）结合到矩阵分解中，来设计视觉贝叶斯个性化排名（VBPR）算法。 He等 [49]扩展VBPR，探索用户的时尚意识和用户在选择项目时考虑的视觉因素的演化。 Yu等。 [191]提出了一种基于美学的服装推荐的耦合矩阵和张量因子分解模型，其中CNN用于学习图像特征和美学特征。 Nguyen等。 [110]提出了一种基于CNN的个性化标签推荐模型。 它利用卷积和最大池化层从图像块中获取视觉特征。 注入用户信息以生成个性化推荐。 为了优化该网络，采用BPR目标来最大化相关和不相关标签之间的差异。 Lei等。 [84]提出了一个具有CNN的比较深度倾斜模型用于图像推荐。 该网络包括两个用于图像表示学习的CNN和一个用于用户偏好建模的MLP。 它将两个图像（一个正图像用户喜欢，一个负图像用户不喜欢）与用户进行比较。 训练数据由三元组组成： ![](img/img104.png)  （用户 ![](img/img105.png)  ，正面形象 ![](img/img106.png)  ，负面图像 ![](img/img107.png)  ）。 假设用户与正面图像之间的距离  ![](img/img108.png) 应该比用户和负面图像之间的距离更近  ![](img/img109.png)  ，其中 ![](img/img110.png) 是距离度量（例如欧氏距离）。  ConTagNet [118]是一种上下文感知标签推荐系统。 图像特征由CNN学习。 上下文表示由两层全连接的前馈神经网络处理。 将两个神经网络的输出连接起来并放入softmax函数以预测候选标签的概率。

用于文本特征提取的CNN 。 DeepCoNN [202]采用两个并行的CNN来模拟评论文本中的用户行为和项目属性。 该模型通过利用评论文本的丰富语义表示，使用 CNN 来缓解稀疏性问题并增强模型可解释性。 它利用单词嵌入技术将评论文本映射到低维语义空间，并保留单词序列信息。 然后，提取的评论表示连续通过最大池化层、全连接层和具有不同核的卷积层。 用户网络 ![](img/img41.png) 和项目网络 ![](img/img42.png) 的输出最终连接作为预测层的输入，其中应用分解机来捕获它们的交互，来进行评分预测。 Catherine 等  [11]提到，只有在目标用户为目标项目编写的评论文本在测试时可用时，DeepCoNN才能正常工作，这是不合理的。 因此，他们通过引入潜在层来扩展它来表示目标用户 - 目标项目对。 此模型在验证/测试期间不访问评论，并且仍然可以保持良好的准确性。 Shen等  [130]建立了一个电子学习资源推荐模型。 它使用CNN从学习资源的文本信息中提取项目特征，如学习资料的介绍和内容，并使用[153]的相同程序进行推荐。  ConvMF [75]使用与CDL类似的方式将CNN与PMF相结合。  CDL使用自编码器来学习项目特征表示，而ConvMF使用CNN来学习高级项目表示。  ConvMF相对于CDL的主要优点是CNN能够使用词嵌入和卷积核，捕获更准确的项目上下文信息。  Tuan 等  [148]建议使用CNN来学习项目内容信息（例如，名称，描述，标识符和类别）的特征表示形式，来增强基于会话的推荐的准确性。

用于音频和视频特征提取的CNN 。 Van 等 [153]建议使用CNN从音乐信号中提取特征。 卷积核和池化层允许多个时间段的操作。 这种基于内容的模型可以缓解音乐推荐的冷启动问题（音乐尚未消耗）。 Lee 等 [83]建议使用著名的CNN模型ResNet提取音频特征。 该推荐在类似于CML的协同度量学习框架中执行。

基于CNN的协同过滤。 直接将CNN应用于普通协同过滤也是可行的。 例如，He等。 [51]建议使用CNN来改进NCF并提出ConvNCF。 它使用外部产品而不是点积来模拟用户项交互模式。 CNN应用于外部产品的结果，并且可以捕获嵌入维度之间的高阶相关性。 Tang等。 [143]呈现了具有CNN的顺序推荐（具有用户标识符），其中两个CNN（分层和垂直）用于对联合级序列模式进行建模并且跳过用于序列感知推荐的行为。

用于推荐的图CNN。 图卷积网络是非欧几里得数据的强大工具，例如：社交网络，知识图，蛋白质交互网络等[77]。 推荐区域中的交互也可以被视为这样的结构化数据集（二分图）。 因此，它也可以应用于推荐任务。 例如，Berg等 [6]建议将推荐问题视为使用图CNN的链接预测任务。 该框架使得将用户/项目方信息，例如社交网络和项目关系，集成到推荐模型中变得容易。 Ying等。 [190]建议使用图CNN来进行Pinterest中的推荐 \[\*\]  。 该模型使用随机游走和图CNN，从图结构以及项目特征信息生成项目嵌入，并且适用于非常大规模的网络推荐系统。 所提出的模型已经部署在Pinterest中，来解决各种现实世界的推荐任务。

## 基于循环神经网络的推荐

RNN非常适合顺序数据处理。 因此，它成为处理交互的时间动态，用户行为和顺序模式，以及具有顺序信号（如文本，音频等）的辅助信息的自然选择。

没有用户标识符的基于会话的推荐。 在许多现实世界的应用或网站中，系统通常不会打扰用户登录，因此它无法访问用户的标识符及其长期消费习惯或长期兴趣。 但是，会话或cookie机制使这些系统能够获得用户的短期偏好。 由于训练数据的极度稀疏，这在推荐系统中是相对不受欢迎的任务。 最近的进展证明了RNN在解决这个问题方面的效果[56,142,176]。

GRU4Rec 。 Hidasi等 [56]提出了一个基于会话的推荐模型GRU4Rec，基于GRU（如图 6a）。 输入是实际的会话状态，带有 1-of-N 编码，其中`N`是物品的数量。 如果相应的项在此会话中处于活动状态，则坐标将为 1，否则为0。输出是每个项目在会话中成为下一个项的可能性。 为了有效地训练所提出的框架，作者提出了一种会话并行的小批量算法，和一种用于输出的采样方法。 排名损失为 TOP1 并具有以下形式：

![](img/img111.png) (12)

其中 ![](img/img112.png) 是样本大小， ![](img/img113.png) 和 ![](img/img114.png) 是负面项目 ![](img/img7.png) 和正面项目 ![](img/img95.png) 在会话 ![](img/img115.png) 中的得分， ![](img/img116.png) 是 sigmoid 函数。 最后一项用于正则化。 注意，BPR损失也是可行的。 最近的一项工作[55]发现[56]中定义的原始TOP1损失和BPR损失受到梯度消失问题的影响，因此，提出了两种新的损失函数：TOP1-max和BPR-max。

后续工作[142]提出了几种进一步改进该模型的策略：（1）通过序列预处理和dropout正则化来扩展点击序列；（2）适应时间变化，通过使用完整的训练数据来预训练，并使用最近的点击序列微调模型；（3）使用教师模型和特权信息来改善模型 ；（4）使用项目嵌入来减少参数数量，以便更快地计算。

Wu等 [176]为真实世界的电子商务网站设计了基于会话的推荐模型。 它利用基本RNN根据点击历史预测用户下次购买的内容。 为了最小化计算成本，它只保留有限数量的最新状态，同时将旧状态折叠为单个历史状态。 该方法有助于权衡计算成本和预测准确性。 Quadrana 等 [117]提出了基于会话的用于推荐的分层递归神经网络。 当存在用户标识符时，该模型可以处理会话感知推荐。

上述三个基于会话的模型不考虑任何辅助信息。 两个扩展[57,132]表明辅助信息对提升会话推荐质量有影响。 Hidasi等 [57]引入了基于会话的并行推荐架构，该架构利用三个GRU来学习身份单热向量，图像特征向量和文本特征向量的表示。 这三个GRU的输出被加权连接并放入非线性激活，来预测该会话中的下一个项目。 Smirnova等 [132]提出了一种基于条件RNN的基于上下文感知会话的推荐系统。 它将上下文信息注入输入和输出层。 这两个模型的实验结果表明，包含额外信息的模型优于仅基于历史交互的模型。

尽管RNN在基于会话的推荐中取得了成功，但Jannach等 [68]表明，简单的邻域方法可以获得精度与GRU4Rec相同的结果。 将邻域与RNN方法相结合通常可以获得最佳性能。 这项工作表明，最近的工作中的一些基线没有充分证明和正确评估。 可以在[103]中找到更全面的讨论。

用户标识符的顺序推荐。 与基于会话的推荐系统不同，其中通常不存在用户标识符。 以下研究涉及带有已知用户标识的顺序推荐任务。

循环推荐网络（RRN） [175]是建立在RNN上的非参数推荐模型（如图 6B 所示）。 它能够模拟项目的季节性演化和用户偏好随时间的变化。  RRN使用两个LSTM网络作为积木来模拟动态用户状态 ![](img/img117.png) 和项目状态 ![](img/img118.png)  。 同时，考虑到用户长期兴趣和项目静态特征等固定属性，该模型还结合了用户和项目的固有潜在属性： ![](img/img119.png) 和 ![](img/img120.png)  。 由用户 ![](img/img7.png) 给出，在时间 ![](img/img104.png) 上的项目的预测评分 ![](img/img95.png) 定义为：

![](img/img121.png) (13)

其中 ![](img/img117.png) 和 ![](img/img118.png) 从LSTM学习， ![](img/img119.png) 和 ![](img/img120.png) 通过标准矩阵分解学习。 优化是最小化预测和实际评分值之间的平方误差。

Wu 等 [174]通过同时对文本评论和评分进行建模，进一步改进了RRN模型。 与大多数文本评论扩展型推荐模型[127,202]不同，此模型旨在使用具有用户和项目潜在状态的字符级LSTM网络生成评论。 评论生成任务可以被视为促进评分预测的辅助任务。 该模型能够提高评分预测的准确性，但不能生成连贯且可读的评论文本。 下文中介绍的NRT [87]可以生成可读的评论提示。 Jing等 [73]提出了一个多任务学习框架，可以同时预测用户的返回时间和推荐项目。 返回时间预测由生存分析模型驱动，它设计用于估计患者生存概率。 作者修改此模型，使用LSTM来估计客户的返回时间。 项目推荐也通过LSTM从用户过去的会话动作执行。 与上述基于会话的推荐系统不同，该推荐系统侧重于在同一会话中进行推荐，该模型旨在提供会话间的推荐。 Li 等 [91]提出了一个行为密集型的顺序推荐模型。 该模型由两部分组成：神经项目嵌入和判别行为学习。 后一部分由两个LSTM组成，分别用于会话和偏好行为学习。 Christakopoulou 等 [24]设计了一个带有RNN的交互式推荐系统。 提出的框架旨在解决交互推荐中的两个关键任务：提问和回答。 RNN用于处理这两项任务：根据用户最近的行为（例如，观察事件）预测用户可能会问的问题并预测响应。 Donkers等 [35]设计了一种新型的门控循环单元，来明确表示个人用户的下一个项目推荐。

![](img/img/fig6.jpg)

**图 6：**插图：（a）使用RNN的基于会话的推荐；（b）循环推荐网络；（c）基于受限玻尔兹曼机的协同过滤。

使用RNN学习特征表示。 对于具有顺序模式的辅助信息，使用RNN作为表示学习工具是可取的选择。

Dai 等 [29]提出了一个共同进化的潜在模型，来捕捉用户和项目潜在特征的共同演化特性。 用户和项目之间的交互在推动用户偏好和项目状态的变化方面起着重要作用。 为了对历史交互进行建模，作者建议使用RNN自动学习来自用户和项目特征的变迁，进化和共同演化的影响的表示。

Bansal等 [5]建议使用GRU将文本序列编码为潜在因子模型。 这种混合模型解决了热启动和冷启动问题。 此外，作者采用了多任务正则化器来防止过拟合并减小训练数据的稀疏性。 主要任务是评分预测，而辅助任务是项目元数据（例如标签，流派）预测。

Okura等。 [113]建议使用GRU来学习用户浏览历史（浏览的新闻）的更具表现力的聚合，并使用潜在因子模型推荐新闻文章。 与传统的基于单词的方法相比，结果显示出显着的改进。 该系统已完全部署到在线生产服务，每天为超过一千万的独立用户提供服务。

Li 等 [87]提出了一个多任务学习框架NRT，用于预测评分以及同时为用户生成文本提示。 生成的提示提供简明的建议，并预测用户对某些产品的体验和感受。 评分预测任务由项目和用户潜在因素 ![](img/img122.png)，![](img/img123.png) 上的非线性层建模，其中 ![](img/img124.png) 和 ![](img/img125.png)  （不一定相等）是用户和项目的潜在因素维度。将预测评分 ![](img/img5.png) 和两个潜在因子矩阵馈送到GRU中以产生提示。 这里， ![](img/img5.png) 用作上下文信息来决定生成的提示的情绪。 多任务学习框架使整个模型能够在端到端的范式中得到有效的训练。

Song 等 [135]设计了一个时态DSSM模型，该模型将RNN集成到DSSM中进行推荐。 基于传统的DSSM，TDSSM将左侧网络替换为项目静态特征，将右侧网络替换为两个子网络，来建模用户静态特征（具有MLP）和用户时间特征（具有RNN）。

## 基于受限玻尔兹曼机的推荐

Salakhutdinov等 [123]提出了一种基于受限玻尔兹曼机的推荐系统（如图 6C 所示）。 据我们所知，它是第一个建立在神经网络上的推荐模型。  RBM的可见单元限于二进制值，因此，评分得分以单热向量表示来适应该限制。 例如，[0,0,0,1,0]表示用户给该项目评分4。 让 ![](img/img126.png) 表示固定大小为 ![](img/img127.png) 的隐藏单元。 每个用户都有一个具有共享参数的唯一RBM。 假设用户评价 ![](img/img23.png) 个电影，可见单元的数量为 ![](img/img23.png)  ，让 ![](img/img100.png) 是一个 ![](img/img128.png) 矩阵，其中 ![](img/img129.png)，如果用户 ![](img/img6.png) 给电影 ![](img/img7.png) 打分为 ![](img/img130.png)，否则为 ![](img/img131.png)。 然后：

![](img/img132.png) (14)

其中 ![](img/img133.png) 表示电影 ![](img/img7.png)的评分 ![](img/img130.png)  和隐藏单元 ![](img/img95.png) 之间连接的权重， ![](img/img134.png) 是评分 ![](img/img130.png) 对于电影 ![](img/img7.png) 的偏差，![](img/img135.png) 是隐藏单元 ![](img/img95.png) 的偏差。RBM不易处理，但可以通过对比发散（CD）算法[45]来学习参数。 作者进一步提出使用条件RBM来结合隐式反馈。 这里的实质是，用户通过给出评分来隐含地告诉他们的偏好，无论他们如何评价项目。

上述RBM-CF是基于用户的，其中给定用户的评分限制在可见层上。 与之类似，如果我们将给定项目的评分限制在可见层上，我们可以轻松设计基于项目的RBM-CF。 Georgiev等 [42]建议将基于用户和基于项目的RBM-CF组合在一个统一的框架中。 在这种情况下，可见单元由用户和项目隐藏单元确定。 Liu等 [100]设计了混合RBM-CF，其中包含项目特征（项目类别）。 该模型也基于条件RBM。 这种混合模型与具有隐式反馈的条件RBM-CF之间存在两个差异：（1）这里的条件层用二元项目类型建模；（2）条件层使用不同连接权重影响隐藏层和可见层。

**表：**基于神经注意的推荐模型的类别。

| 普通注意 | 共同注意 |
| --- | --- |
| [14, 44, 70, 90, 99, 101, 127, 145, 169, 189] | [62, 146, 193, 194, 205] |

## 基于神经注意力的推荐

注意力机制是由人类视觉注意力驱动的。 例如，人们只需要关注视觉输入的特定部分来理解或识别它们。 注意力机制能够从原始输入中滤除无信息特征，并减少噪声数据的副作用。 这是一种直观但有效的技术，近年来在计算机视觉[3]，自然语言处理[104,155]和语音识别[22,23]等领域引起了相当多的关注。 神经注意力不仅可以与MLP，CNN和RNN一起使用，还可以独立地解决一些任务[155]。 将注意力机制集成到RNN中，使RNN能够处理长而嘈杂的输入[23]。 虽然LSTM可以在理论上解决长期记忆问题，但在处理远程依赖时仍然存在问题。 注意力机制提供了更好的解决方案，并帮助网络更好地记忆输入。 基于注意力的CNN能够捕获输入中信息量最大的元素[127]。 通过将注意力机制应用于推荐系统，可以利用注意力机制来过滤无信息内容并选择最具代表性的项目[14]，同时提供良好的可解释性。 虽然神经注意力机制并不完全是一种独立的深度神经技术，但由于其广泛使用，仍然值得单独讨论。

注意力模型使用注意力得分来学习输入的注意力。 计算注意力得分是神经注意力模型的核心。 基于计算注意力得分的方式，我们将神经注意力模型分为（1）标准的普通注意力和（2）共同注意力。 普通注意力利用参数化的背景向量来学习注意力，而共同注意力涉及从两个序列学习注意力权重。 自我注意力是共同关注的一个特例。 最近的工作[14,44,127]展示了注意力机制在提高推荐效果方面的能力。 表 ?? 总结了基于注意力的推荐模型。

使用普通注意力的推荐

Chen 等。 [14]通过在潜在因子模型中引入二级注意力机制，提出了一种注意力协同过滤模型。 它由项目级别和组件级别的注意力组成。 项目级注意力用于选择最具代表性的项目来表示用户。 组件级别的注意力旨在从每个用户的多媒体辅助信息中捕获最丰富的信息。 Tay 等 [145]为协同度量学习提出了基于记忆的注意力。 它引入了潜在关系向量，通过CML的关注来习得。 Jhamb等 [70]提出，使用注意力机制来提高基于自编码器的CF的性能。Liu等 [99]提出了一种基于短期注意力和记忆优先级的模型，其中长期和短期用户兴趣都集成在基于会话的推荐中。 Ying等 [189]提出了序列推荐的分层注意力模型。 两个注意力网络用于模拟用户的长期和短期兴趣。

向RNN引入注意力机制可以显着提高其性能。 Li等 [90]提出了一种基于注意力的LSTM模型，用于标签推荐。 这项工作利用RNN和注意力机制的优势，来捕获序列属性并识别来自微博帖子的信息性单词。 Loyala等 [101]提出了一种编码器 - 解码器架构，注重用户会话和意图建模。 该模型由两个RNN组成，可以以更具表现力的方式捕捉过渡性规律。

普通注意力也可以与CNN一起用于推荐任务。 Gong等 [44]提出了一个基于注意力的CNNs系统，用于微博中的`#`标签推荐。 它将主题标签推荐视为多标签分类问题。 所提出的模型由全局通道和局部注意力通道组成。 全局通道由卷积滤波器和最大池化层组成。 所有单词都在全局通道的输入中编码。 局部注意力通道具有一个具有给定窗口大小和阈值的注意层，来选择信息性词语（在本工作中称为触发词）。 因此，只有触发词在后续层中起作用。 在后续工作[127]中，Seo等 利用与[44]相同的两个神经网络（没有最后两层）来学习来自用户和项目评论文本的特征表示，并使用最终层中的点积来预测评分。 Wang等 [169]提出了文章推荐的组合模型，其中CNN用于学习文章表示，并且注意力被用于处理编辑的选择行为的多样化差异。

共同注意力的推荐。Zhang等 [194]提出了一个组合模型AttRec，它通过利用自我注意力和度量学习的强度来改进顺序推荐性能。 它利用自我注意力从最近的交互中学习用户的短期意图，并利用度量学习的优势来学习更具表现力的用户和项目嵌入。 Zhou等 [205]建议使用自我注意力进行用户异构行为建模。 自我注意力是一种简单而有效的机制，并且在顺序推荐任务方面表现出优于CNN和RNN的性能。 我们相信它有能力取代许多复杂的神经模型，预计会有更多的综述。 Tay等 [146]提出了一种基于评论的推荐系统，具有多指针的共同注意力。 共同注意力使模型能够通过用户和项目评论的共同学习来选择信息性评论。 Zhang等 [193]提出了一种基于共同注意力的标签推荐模型，该模型集成了视觉和文本信息。 Shi等 [62]提出了一种神经共同注意力模型，用于带有元路径的个性化排名任务。

## 基于神经自回归的推荐

如上所述，RBM不易处理，因此我们通常使用Contrastive Divergence算法来近似参数[81]上的对数似然梯度，这也限制了RBM-CF的使用。 所谓的神经自回归分布估计器（NADE）是一种易处理的分布估计器，它为RBM提供了理想的替代方案。 受RBM-CF的启发，Zheng等 [204]提出了一种基于NADE的协同过滤模型（CF-NADE）。 CF-NADE模拟用户评分的分布。 在这里，我们提供一个详细的例子来说明CF-NADE的工作原理。 假设我们有4部电影：m1（评分为4），m2（评分为2），m3（评分为3）和m4（评分为5）。 CF-NADE模拟评分向量 ![](img/img136.png) 的联合概率，通过链式规则：  ![](img/img137.png)，其中 ![](img/img138.png) 是用户评分的项目数， ![](img/img139.png) 是`D`元组，是 ![](img/img140.png) 的排列， ![](img/img141.png) 是第  ![](img/img142.png) 个评论的项目的下标， ![](img/img143.png) 是用户给商品 ![](img/img144.png) 的评分。 具体来说，该过程如下：（1）用户给 ![](img/img145.png) 四星的概率，没有任何条件； （2）用户给 ![](img/img146.png) 2星的概率，条件为 ![](img/img145.png) 四星； （3）用户给 ![](img/img147.png)  三星的概率，条件为 ![](img/img145.png) 四星和 ![](img/img146.png)  2星的； （4）用户给 ![](img/img148.png) 五星的概率，条件为 ![](img/img145.png) 四星， ![](img/img146.png)  2星和 ![](img/img147.png)  3星。

理想情况下，电影的顺序应遵循评分的时间戳。 然而，实证研究表明，随机抽取也会产生良好的性能。 该模型可以进一步扩展到深度模型。 在后续文献中，Zheng等 [203]提出结合隐式反馈来克服评分矩阵的稀疏性问题。 Du等 [36]使用用户项目共同自回归方法进一步改进了该模型，该方法在评分估计和个性化排名任务方面具有更好的性能。

## 深度强化学习推荐

大多数推荐模型将推荐过程视为静态过程，这使得难以捕获用户的时间意图并及时响应。 近年来，DRL开始引起人们对个性化推荐的关注[21,107,168,198-200]。 Zhao等 [198]提出了一个DRL框架DEERS，用于在顺序交互设置中提供负反馈和正反馈。 Zhao等 [200]使用DRL探索了页面推荐方案，建议的框架DeepPage能够根据用户的实时操作自适应地优化项目页面。Zheng等。 [200]提出了一个新闻推荐系统DRN，用DRL来应对以下三个挑战：（1）新闻内容和用户偏好的动态变化；（2）纳入用户的退货模式（对服务）；（3）增加建议的多样性。 Chen等 [16]提出了一种强大的深度Q学习算法，用两种策略解决不稳定的奖励估计问题：分层抽样重放和近似后悔奖励。 崔等。 [21]提出用RL和双聚类解决冷启动问题。 Munemasa等[107]建议使用DRL进行商店推荐。

强化学习技术，如上下文 - 强盗方法[86]，已在实际应用中表现出卓越的推荐性能。 深度神经网络增加了RL的实用性，并且可以为设计实时推荐策略建模各种额外信息。

## 基于对抗网络的推荐

IRGAN [162]是第一个将GAN应用于信息检索领域的模型。 具体而言，作者展示了其在信息检索任务中的三个能力，包括：网络搜索，项目推荐和问题回答。 在本综述中，我们主要关注如何使用IRGAN推荐商品。

首先，我们介绍IRGAN的一般框架。 传统的GAN由判别器和生成器组成。 可能在信息检索方面存在两种思维流派，即生成检索和判别检索。 给定查询 ![](img/img150.png)，生成检索假定文档和查询之间存在潜在的生成过程，并且可以通过生成相关文档来实现检索任务 ![](img/img149.png)。给定标记的相关查询 - 文档对，判别式检索学习预测相关性得分 ![](img/img136.png)。IRGAN的目标是将这两个想法组合成一个统一的模型，并使它们在GAN中扮演像生成器和判别器这样的极小极大游戏。 生成检索旨在生成类似于真实情况的相关文档，来欺骗判别性检索模型。

形式上，让 ![](img/img151.png) 指代用户的相关性（偏好）分布。 生成检索模型  ![](img/img152.png) 试图近似真实的相关性分布。 判别性检索 ![](img/img153.png) 试图区分相关文档和不相关文档。 与GAN的目标函数类似，总体目标如下：

![](img/img154.png) (15)

其中 ![](img/img155.png)，![](img/img116.png) 代表 sigmoid 函数，![](img/img20.png) 和 ![](img/img156.png) 分别是生成和判别检索的参数。参数 ![](img/img20.png) 和 ![](img/img156.png) 可以用梯度下降交替学习。

为逐点相关性估计构造上述目标方程。在某些特定任务中，应该采用成对范式来生成更高质量的排名列表。这里，假设由 softmax 函数给出：![](img/img152.png)  

![](img/img157.png) (16)

![](img/img158.png)是文档 ![](img/img149.png) 从查询 ![](img/img150.png) 生成的机会。在显式世界的检索系统中，两者 ![](img/img158.png) 和 ![](img/img153.png) 都是特定于任务的。它们可以具有相同或不同的公式。为方便起见，作者使用相同的函数对它们进行了建模，并将它们定义为：![](img/img159.png) 和 ![](img/img160.png)。在项目推荐方案中，作者采用矩阵分解来表示 ![](img/img161.png)。它可以用其他高级模型代替，例如分解机或神经网络。

He 等\[52\]提出了一种对抗性的个性化排名方法，使用对抗性训练增强了贝叶斯个性化排名。它在原始BPR目标和对手之间进行极小极大游戏，增加噪音或排列来最大化BPR损失。Cai等\[9\]为引文文献网络提出了一种基于GAN的表示学习方法，可以有效地解决个性化的引文推荐任务。Wang等\[164\]建议使用GAN为基于存储器网络的流推荐系统生成负样本。实验表明，所提出的基于GAN的采样器可以显着提高性能。

## 用于推荐的深度混合模型

凭借深度神经网络的良好灵活性，可以集成许多神经积木，来形成更强大和更具表现力的模型。尽管有很多可能的组合方式，但我们建议混合模型应该针对特定任务而合理并精心设计。在这里，我们总结了据证明在某些应用领域有效的现有模型。

CNN和自编码器。基于协同知识嵌入（CKE）\[192\]将CNN与自编码器相结合，用于图像特征提取。 CKE可以被视为CDL的另一步。 CDL仅考虑项目文本信息（例如文章摘要和电影情节），而CKE使用不同嵌入技术，利用结构内容，文本内容和视觉内容。结构信息包括项目的属性以及项目和用户之间的关系。 CKE采用TransR \[96\]，一种异构网络嵌入方法，用于解释结构信息。同样，CKE使用SDAE从文本信息中学习特征表示。至于视觉信息，CKE采用堆叠卷积自编码器（SCAE）。SCAE通过用卷积层替换全连接的SDAE层来有效利用卷积。推荐过程类似于CDL的概率形式。

CNN和RNN。Lee等 \[82\]提出了一个带有RNN和CNN的深度混合模型，用于引用推荐。引用推荐被视为，在给定查询文本或对话的情况下，生成有序的引用列表的任务（每个对话包含一系列推文）。它应用CNN来学习重要的局部语义，并将它们映射到分布向量。 LSTM进一步处理这些分布向量，来计算目标引用与给定推文对话的相关性。整体架构如图12（a）所示。

Zhang等\[193\]提出了基于CNN和RNN的混合模型，用于标签推荐。给定带有相应图像的推文，作者利用CNN从图像中提取特征，并利用LSTM从推文中学习文本特征。同时，作者提出了一种共同关注机制来模拟相关影响并平衡文本和图像的贡献。

Ebsesu等\[38\]提出了一个神经引文网络，它将CNN与RNN集成在一个编码器 - 解码器框架中，用于引用推荐。在此模型中，CNN充当编码器，捕获来自引用上下文的长期依赖性。给定所有先前的单词以及CNN获得的表示，RNN用作解码器，学习所引用的论文的标题中的单词的概率。

Chen 等\[17\]提出了一个集成CNN和RNN的集成框架，用于个性化（视频中）关键帧的推荐，其中CNN用于学习关键帧图像的特征表示，RNN用于处理文本特征。

RNN和自编码器。前面提到的协同深度学习模型缺乏鲁棒性，无法对文本信息序列进行建模。Wang 等 \[160\]进一步利用集成RNN和去噪自编码器来克服这些限制。作者首先设计了一种名为鲁棒复现网络的泛化RNN。基于强大的循环网络，作者提出了称为CRAE的分层贝叶斯推荐模型。CRAE还包括编码和解码部分，但它用RNN替换前馈神经层，这使得CRAE能够捕获项目内容信息的顺序信息。此外，作者设计了通配符去噪和β池化技术来防止模型过拟合。

具有DRL的RNN。Wang 等。[163\]建议将监督的深度强化学习与RNNs结合起来用于治疗推荐。该框架可以从指标信号和评估信号中学习处方策略。实验表明，该系统可以自动推断和发现最佳处理方法。我们相信这是一个有价值的话题，有益于社会利益。