## 四、现状

对ConvNet架构的各个组件的作用的审查强调了卷积块的重要性，卷积块主要负责网络捕获的大多数抽象。相比之下，这个组件仍然是最不被理解的处理块，因为它需要最重要的学习。本章回顾了试图了解各种ConvNet层学习内容的当前趋势。鉴于这些趋势，将突出显示仍存在的各种关键性开放问题。

### 4.1当前趋势

虽然各种ConvNet模型继续在几个计算机视觉应用中进一步推动最先进的技术，但对这些系统如何以及为何如此有效运行的理解是有限的。这个问题引起了各种研究人员的兴趣，并且在回应中出现了几种方法来理解ConvNets。一般来说，这些方法可以分为三个方面：那些依赖于学习过滤器和提取的特征图的可视化的方法，那些依赖于消融研究的方法，这些研究是从理解视觉皮层的生物学方法和依赖于最小化学习的方法中获得的。通过将分析原理引入其网络设计中。本节将简要回顾这些方法中的每一种。

#### 4.1.1通过可视化了解ConvNets

尽管文献中已经提出了几种方法来可视化由ConvNets提取的特征图，但在本节中我们将集中讨论两种最突出的方法并讨论它们的不同变化。

ConvNet可视化的第一种方法被称为以数据集为中心的方法[151]，因为它依赖于使用来自数据集的输入探测网络以找到网络中的最大响应单元。属于这一类别的最早的方法之一被称为DeConvNet [154]，其中可视化分两步实现。首先，向ConvNet提供来自数据集的若干图像，并记录对该输入最大响应的特征图。其次，使用DeConvNet架构将这些特征映射投射回图像空间，该架构由反转所用ConvNet操作的块组成。特别是，DeConvNet通过使用所考虑的ConvNet中的学习过滤器的转置来反转卷积运算（_，即_。执行“去卷积”）。这里值得注意的是，不能保证转置转换操作。对于“取消汇集”，DeConvNet依赖于记录ConvNet中与最大池化响应相对应的位置，并使用这些位置“取消汇集”或对特征映射进行上采样。这些操作总结在图4.1中。

| ![](img/x44.png) | ![](img/x45.png) |
| （一个） | （b）中 |

图4.1：DeConvNet构建块。 （a）说明DeConvNet操作，该操作可应用于将从ConvNet的任何层提取的特征映射投影回图像空间。 （b）通过使用“开关”说明“非汇集”操作，“开关”对应于响应最大汇集操作的位置。图[154]再现。

![](img/x46.png)

图4.2：通过在标准ConvNet架构的各个层（如AlexNet [88]）应用DeconvNet获得的可视化。图[154]转载。

这些方法产生的典型可视化如图4.2所示。总体而言，这些可视化显示网络中的早期层倾向于捕获低级特征，例如定向条和边，_，即_。在较低层学习的滤波器类似于定向带通滤波器。相比之下，在更高层的特征捕获从简单纹理到更复杂对象的进展。有趣的是，这些可视化倾向于从图像中保留高水平的细节，从而在网络中产生高响应。事实上，似乎这些可视化倾向于强调输入图像的边缘，并且主要揭示负责高响应的图像部分（_即_。它们可被视为查找输入图像的方法输入图像的高对比度点，主要揭示负责高分类结果的部分）。受这些观察的启发，属于以数据集为中心的范式的其他方法提出了更简单的方法来可视化网络正在学习的内容。例子包括逐步从图像中去除部分的方法，产生高响应以突出显示哪些部分负责高响应[156,157]。从这些方法中得出的一些结论是，对象主要负责识别场景[156]或更一般地说，当我们可视化网络的更高层时，对象检测器会出现[157]。

ConvNet可视化的第二种方法被称为以网络为中心的方法[151]，因为它仅使用网络参数而无需任何其他数据用于可视化目的。这种方法最初是在深层信念网络[37]的背景下引入的，后来应用于ConvNets [133]。在这种情况下，通过合成将最大化一些神经元（或滤波器）响应的图像来实现可视化。例如，从产生类别分数![](img/tex192.gif)的网络的最后一层开始，以及初始化为随机噪声的图像![](img/tex193.gif)，目标是修改图像，使其属于类![](img/tex194.gif)的分数]最大化。这个优化问题在[133]中定义

![](img/tex195.gif)（4.1）

其中![](img/tex119.gif)是正则化参数。这里![](img/tex196.gif)正则化用于惩罚大值。属于这种范式的大多数其他方法试图解决相同的优化问题，同时执行不同的正则化技术，例如总变差正则化以强制平滑并避免合成图像中的高频内容[104]或简单剪切不强烈参与的像素过滤器的响应仅突出显示负责过滤器激活的模式[151]。

当用于最大化（4.1）中定义的类别分数时，以网络为中心的方法产生的典型可视化如图4.3所示。通常，这些可视化表明网络正在学习高级形状，负责区分各种物体（_例如_。当目标类是动物面部时，眼睛，鼻子和耳朵）;但是，这些功能的确切位置无关紧要。因此，这些可视化意味着网络逐渐学习不变性（_，例如_。它在较高层变为位置不可知），正如使用各种池化操作所预期的那样。然而，当这种以网络为中心的可视化技术应用于反转较低层时，它并不一定表明它们正在学习较低级别的特征，例如边缘，而不是以数据集为中心的技术。例如，在图4.3（b）中，可以看出较低层保留了图像中存在的大部分摄影信息。更一般地，理解ConvNets的可视化方法的主要限制是解释的主观性质，其通常基于该方法的作者的视觉检查。

| ![](img/x47.png) |
| (a) |
| ![](img/x48.png) |
| (b) |

图4.3：通过在网络中心方法中对图像空间应用优化而获得的可视化。 （a）通过最大化属于各种类别的得分而获得的可视化，如下面每个图像所示。图[133]转载。 （b）通过最大化各层的标准网络响应而获得的可视化，如下图所示。图[104]转载。

#### 4.1.2通过消融研究了解ConvNets

另一种流行的方法是阐明广泛使用的ConvNet功能，即所谓的网络消融研究。事实上，许多着名的ConvNet论文（_，例如_。[23,154,134,144,41,29,78]）在他们的实验部分包括消融研究，其目标是隔离不同的成分查看删除或添加块如何影响整体性能的网络。

这些消融研究有可能引导ConvNet从业者走向“良好实践”，以在不同的应用中实现更高的性能。例如，ConvNets背景下最早的消融研究之一揭示了即使在使用随机初始化网络时也需要进行适当的整流和归一化[77]。其他工作揭示了在所有层使用较小过滤器时更深层表示的重要性[23,135]。还有其他研究，调查了预训练和微调的作用以及特征的数量，位置和大小。这些调查进一步突出了跨任务从ConvNets中提取的特征的可转移性[1]。

更有意思的是，其他工作提出要剖析ConvNets以调查每个组成部分对所学表征的可解释性的影响[6]。该方法依赖于具有像素级注释的数据集，其中每个像素被分配若干“概念”标签，其包括颜色，纹理，对象和场景标签。评估ConvNet中的每个单元的能力，以生成与某个基于概念的分割掩码![](img/tex197.gif)匹配的分割掩码。特别地，网络中的每个特征映射![](img/tex198.gif)被转换为二进制掩码![](img/tex199.gif)，其中仅当像素的激活超过某个预设阈值时才将像素设置为![](img/tex9.gif)。接下来，每个单位![](img/tex182.gif)根据其分割给定概念![](img/tex194.gif)的能力分配一个分数，根据

![](img/tex200.gif)（4.2）

其中![](img/tex201.gif)是集合的基数。通过这种方法，每个单元的可解释性基于其生成良好分割掩模的能力来定义。该测量表明，较低层中的单元能够生成更好的基于颜色或纹理的掩模，而较高层可以生成更好的对象和场景分割。与数据集为中心的可视化方法一致，这一观察结果表明，较低层是学习过滤器，捕获较低层次的概念，而较高层层次学习更多抽象特征，如对象部分。这种方法还允许系统地分析各种非线性和训练策略对可解释性的影响，并揭示出更高的表现并不总是产生高度可解释的单位。例如，已经表明，诸如批量归一化之类的正则化技术非常简单地影响该方法中定义的单元的可解释性。此外，与广泛使用的ImageNet培训相比，发现在场景数据集上训练的网络产生更多可解释的单元。不幸的是，这种方法的一个主要缺陷是它们对可解释性的定义在很大程度上取决于用于评估的数据集。换句话说，能够捕获数据集中未表示的概念的ConvNet单位将产生较低的IoU分数;因此，即使该概念在视觉上是可解释的，也被认为不能通过这种方法解释。因此，该方法可能会遗漏由负责更高性能的网络组件揭示的其他重要方面。

#### 4.1.3通过受控设计了解ConvNets

理解ConvNets的另一种方法是通过将先验注入网络设计来最小化学习参数的数量。例如，一些方法减少每层学习过滤器的数量，并包括每层中学习过滤器的变换版本以模拟旋转不变性，_，例如_。 [100,158]。其他方法依赖于用基组替换学习过滤器而不是学习过滤器参数，而是学习如何组合基组以在每层形成有效过滤器，_，例如_。 [75,28,148,100,158]。还有其他方法，通过全面手工制作网络并使其适应特定任务，推动将先行者注入其网络设计的想法，这产生了特别可解释的网络，_，例如_。 [15,113,60]。大多数属于这种范式的技术先前已在第3章第3.1.2节中详细讨论过。

### 4.2打开问题

该报告记录了各种新型ConvNet架构和构建块的设计取得的重大进展。虽然这一进展在几个计算机视觉应用中产生了新的先进技术，但了解这些ConvNets如何实现这些结果却落后了。此外，对这些方法的性能限制（_，例如_。失效模式）几乎没有理解。因此，揭示这些ConvNets捕获的信息变得尤为重要。目前，专注于理解ConvNets的方法在本章所讨论的相关文献中变得明显。然而，虽然这里讨论的几种技术都采取了很好的措施，但它们都留下了尚未解决的悬而未决的关键问题。

实际上，针对解释ConvNets的不同技术的评论显示，最广泛采用的方法依赖于可视化。然而，基于可视化技术的最大缺陷之一是它们将对复杂和高度非线性模型的理解减少到对各种潜在解释开放的单个图像。值得注意的是，这些可视化根据所采用的技术而变化（_，例如_。以数据集为中心，以网络为中心，如图4.2和4.3所示），并且通常还取决于所考虑的体系结构以及培训策略[6]。他们的解释也非常主观。更重要的是，在最近的一项研究中显示，用随机噪声替换特征图的强响应并通过DeConvNet架构将其传播回产生与投影回特征图响应本身时所获得的相似的可视化[105]。因此，本研究表明，以数据集为中心的可视化并不一定能揭示特定要素图捕获的内容，因为它们本身依赖于网络学习的参数来生成可视化。因此，基于此讨论，以下几点成为基于可视化方法的潜在关键方法：

*   首先，通过引入评估所生成图像的质量和/或含义的度量，开发使可视化评估更客观的方法是至关重要的。

*   此外，虽然看起来以网络为中心的可视化方法更有前景，因为他们不依赖于网络本身来生成可视化（_，例如_ .DeConvNet），似乎有必要将他们的评估过程标准化为一种可能的解决方案是使用基准来生成在相同条件下训练的可视化和网络。这种标准化可以反过来允许基于度量的评估而不是当前基于解释的分析。

*   另一种方法是同时可视化多个单元，以便更好地捕获研究中表示的分布式方面，即使在遵循受控方法的情况下也是如此。

考虑到消融研究，虽然它们允许隔离网络的各个部分以识别负责更好性能的组件，但它们无法真正阐明网络学习的内容，因为他们试图解释ConvNets“孤立的高度交织的组件。值得注意的是，在他们目前的应用中，消融研究只是用来收集绩效的几个百分点，而不是从理解的角度真正增加价值。这里，基于消融的方法可能有趣的方法包括：

*   使用通用且系统组织的数据集，捕获计算机视觉中常见的不同挑战（_，例如_。视点和光照变化），并且需要具有更高复杂程度的类别（_，例如_纹理，零件和物体。实际上，最近引入了这种初始数据集[6]。对这样的数据集使用消融研究，以及对所产生的混淆矩阵的分析，可以精确定位ConvNet架构的故障模式，从而提供更好的理解。

*   此外，有关多个协调消融如何影响性能的系统研究很有意思。这些研究应该将洞察力扩展到孤立单位的表现之外

最后，尽管可视化和消融研究方法存在理解ConvNets的缺陷，但它们仍然对ConvNet的缺点有所了解，例如学习过滤器的冗余（_，例如_。见图3.8）和重要性某些非线性（_，例如_。[77,23]）。这些见解反过来用于ConvNet实现的更加可控的方法，这些方法不太依赖于数据，更重要的是不那么模糊（_，例如_。[15,113,75,78,60]）。这些受控方法正在成为未来研究的一个有前途的方向，因为它们可以更深入地理解这些系统相对于纯粹基于学习的方法所采用的操作和表示。实际上，前一章回顾了许多这样的见解。反过来，它们也有可能根据其精确的系统规格支持更严格的性能界限。这里有趣的方法包括：

*   逐步修复网络参数并分析对网络行为的影响。例如，一次一层地修复卷积核参数（基于手头任务的一些先验知识），以分析每层采用的内核的适用性。这种渐进的方法有可能揭示学习的作用，也可以用作初始化，以最大限度地减少培训时间。

*   类似地，可以通过分析输入信号属性（_，例如_）来研究网络架构本身的设计（_，例如_。层数或每层滤波器数。）信号的频率内容）。此方法可以帮助调整架构的复杂性以适应应用程序。

*   最后，对网络实现的受控方法的使用可以伴随对ConvNets的其他方面的作用的系统研究，其通常由于关注学习参数而受到较少关注。例子包括调查各种汇集策略以及当大多数学习参数被修复时剩余连接的作用。